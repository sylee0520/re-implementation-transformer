{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenizer.Tokenizer at 0x10cdb61f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tokenizer.load_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15953, 1, 373, 8, 5140]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.encode('I am a president')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 1, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "onehot = F.one_hot(torch.tensor(a), 16000)\n",
    "onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputs = torch.rand(64, 20).long()\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingLayer(\n",
       "  (embedding): Embedding(20, 512, padding_idx=0)\n",
       "  (linear): Embedding(512, 20, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import EmbeddingLayer\n",
    "\n",
    "embed = EmbeddingLayer(num_embeddings=20, embedding_dim=512, padding_idx=0, layer_mode='embedding')\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = embed(inputs)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sqrt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tokenizer import Tokenizer\n",
    "from datasets import Dataset\n",
    "num_embeddings=16000\n",
    "embedding_dim=512\n",
    "padding_idx=0\n",
    "model_dim=512\n",
    "q_dim=64\n",
    "k_dim=64\n",
    "v_dim=64\n",
    "n_heads=8\n",
    "in_dim=512\n",
    "hid_dim=2048\n",
    "out_dim=512\n",
    "max_seq_len=20\n",
    "N=6\n",
    "mask=True\n",
    "\n",
    "tokenizer = Tokenizer().load_model()\n",
    "dataset = Dataset(src='de', trg='en', data_type='train', tokenizer=tokenizer, max_seq_len=20)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=64, shuffle=False, collate_fn=dataset.collate_fn)\n",
    "embed = EmbeddingLayer(num_embeddings=16000, embedding_dim=512, padding_idx=0, layer_mode='embedding')\n",
    "encoder = Encoder(num_embeddings, embedding_dim, padding_idx, model_dim, q_dim, k_dim, v_dim, n_heads, in_dim, hid_dim, out_dim, max_seq_len, N)\n",
    "pe = PositionalEncodingLayer()\n",
    "mha = MultiHeadAttentionLayer(model_dim, q_dim, k_dim, v_dim, n_heads)\n",
    "decoder = Decoder(num_embeddings, embedding_dim, padding_idx, model_dim, q_dim, k_dim, v_dim, n_heads, in_dim, hid_dim, out_dim, max_seq_len, N, mask)\n",
    "decoderlayer = DecoderLayer(model_dim, q_dim, k_dim, v_dim, n_heads, in_dim, hid_dim, out_dim, mask)\n",
    "linear = EmbeddingLayer(num_embeddings=16000, embedding_dim=512, padding_idx=0, layer_mode='linear')\n",
    "transformer = Transformer(num_embeddings=16000, embedding_dim=512, padding_idx=0, \n",
    "                 model_dim=512, q_dim=64, k_dim=64, v_dim=64, n_heads=8,\n",
    "                 in_dim=512, hid_dim=2048, out_dim=512, max_seq_len=20, N=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "output shape:  torch.Size([1280, 16000])\n",
      "tensor([[7.2497e-05, 2.0259e-05, 3.6086e-05,  ..., 1.0539e-04, 2.5765e-05,\n",
      "         3.9717e-05],\n",
      "        [8.3365e-05, 2.2292e-05, 6.9347e-05,  ..., 1.1280e-04, 1.3574e-05,\n",
      "         3.0544e-05],\n",
      "        [1.1523e-04, 4.9236e-05, 4.4523e-05,  ..., 1.1361e-04, 1.3742e-05,\n",
      "         3.8350e-05],\n",
      "        ...,\n",
      "        [7.8031e-05, 2.9709e-05, 5.9426e-05,  ..., 6.5251e-05, 2.7121e-05,\n",
      "         7.3002e-05],\n",
      "        [8.5027e-05, 2.3471e-05, 5.9556e-05,  ..., 5.9697e-05, 2.9138e-05,\n",
      "         6.7957e-05],\n",
      "        [6.1569e-05, 2.2690e-05, 5.9345e-05,  ..., 5.5302e-05, 3.0623e-05,\n",
      "         6.4594e-05]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, outputs = data\n",
    "        print(\"input shape: \", inputs.shape)\n",
    "        print(outputs.shape)\n",
    "        temp = transformer(inputs, outputs)\n",
    "        temp = temp.view(-1, 16000)\n",
    "        print(\"output shape: \", temp.shape)\n",
    "        print(temp)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a38b83aeb1ea4339894febc55f8dc589b6819da101b0f16fbec59eab151f047a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
