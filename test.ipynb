{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenizer.Tokenizer at 0x10cdb61f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tokenizer.load_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15953, 1, 373, 8, 5140]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.encode('I am a president')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 1, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "onehot = F.one_hot(torch.tensor(a), 16000)\n",
    "onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "inputs = torch.rand(64, 20).long()\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingLayer(\n",
       "  (embedding): Embedding(20, 512, padding_idx=0)\n",
       "  (linear): Embedding(512, 20, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import EmbeddingLayer\n",
    "\n",
    "embed = EmbeddingLayer(num_embeddings=20, embedding_dim=512, padding_idx=0, layer_mode='embedding')\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = embed(inputs)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sqrt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tokenizer import Tokenizer\n",
    "from datasets import Dataset\n",
    "num_embeddings=16000\n",
    "embedding_dim=512\n",
    "padding_idx=0\n",
    "model_dim=512\n",
    "q_dim=64\n",
    "k_dim=64\n",
    "v_dim=64\n",
    "n_heads=8\n",
    "in_dim=512\n",
    "hid_dim=2048\n",
    "out_dim=512\n",
    "max_seq_len=20\n",
    "N=6\n",
    "mask=True\n",
    "\n",
    "tokenizer = Tokenizer().load_model()\n",
    "dataset = Dataset(src='de', trg='en', data_type='train', tokenizer=tokenizer, max_seq_len=20)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=64, shuffle=False, collate_fn=dataset.collate_fn)\n",
    "embed = EmbeddingLayer(num_embeddings=16000, embedding_dim=512, padding_idx=0, layer_mode='embedding')\n",
    "encoder = Encoder(num_embeddings, embedding_dim, padding_idx, model_dim, q_dim, k_dim, v_dim, n_heads, in_dim, hid_dim, out_dim, max_seq_len, N)\n",
    "pe = PositionalEncodingLayer()\n",
    "mha = MultiHeadAttentionLayer(model_dim, q_dim, k_dim, v_dim, n_heads)\n",
    "decoder = Decoder(num_embeddings, embedding_dim, padding_idx, model_dim, q_dim, k_dim, v_dim, n_heads, in_dim, hid_dim, out_dim, max_seq_len, N, mask)\n",
    "decoderlayer = DecoderLayer(model_dim, q_dim, k_dim, v_dim, n_heads, in_dim, hid_dim, out_dim, mask)\n",
    "linear = EmbeddingLayer(num_embeddings=16000, embedding_dim=512, padding_idx=0, layer_mode='linear')\n",
    "transformer = Transformer(num_embeddings=16000, embedding_dim=512, padding_idx=0, \n",
    "                 model_dim=512, q_dim=64, k_dim=64, v_dim=64, n_heads=8,\n",
    "                 in_dim=512, hid_dim=2048, out_dim=512, max_seq_len=20, N=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  torch.Size([64, 20])\n",
      "tensor([[[-0.3619, -1.8932,  0.2220,  ...,  0.6452,  1.2097, -0.0408],\n",
      "         [-0.2442, -0.1923,  0.5881,  ..., -0.4934,  1.4692, -0.3951],\n",
      "         [-1.2747, -0.3329, -0.4723,  ..., -0.6529,  0.8831, -0.1407],\n",
      "         ...,\n",
      "         [-0.9701, -0.9186,  0.0088,  ...,  0.1643,  0.7566, -0.7936],\n",
      "         [-0.5507, -0.4464, -0.0563,  ..., -0.0148,  0.2978, -0.6197],\n",
      "         [-0.2137, -0.0523, -0.0150,  ...,  0.2541, -0.1364, -0.9620]],\n",
      "\n",
      "        [[-0.8654, -0.3887, -0.7595,  ...,  0.7377,  0.5791, -2.3734],\n",
      "         [-0.9903, -1.0533, -0.7714,  ...,  0.3701,  1.4329, -1.9459],\n",
      "         [-0.7322, -0.2668, -0.8854,  ...,  0.2119,  0.6180, -2.6303],\n",
      "         ...,\n",
      "         [-0.2287,  0.0519, -0.3272,  ..., -0.1382,  1.1350, -1.8428],\n",
      "         [-0.9960, -0.1186, -0.4556,  ..., -0.9439,  0.9253, -2.3083],\n",
      "         [-1.2612, -0.6043, -0.6711,  ...,  0.5135,  1.3869, -1.0697]],\n",
      "\n",
      "        [[-2.2206, -1.7474, -0.5971,  ..., -0.1833,  0.0938, -0.7577],\n",
      "         [-1.5307, -0.4289, -0.3262,  ..., -0.3154, -0.0793, -1.3600],\n",
      "         [-2.1216, -0.8645, -0.5589,  ..., -0.3627,  1.0280, -0.7574],\n",
      "         ...,\n",
      "         [-1.1888, -0.7752,  0.6251,  ..., -0.8541,  0.6050, -0.8497],\n",
      "         [-0.9410, -1.6163, -0.1805,  ..., -0.6450, -0.2216, -0.3876],\n",
      "         [-1.8862, -1.6235,  0.3089,  ..., -1.0211,  0.2778, -0.8199]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4669, -1.1496,  0.7593,  ..., -0.7233,  0.4903, -1.1016],\n",
      "         [-1.0600, -0.9519,  0.3664,  ...,  0.1024,  1.0872, -0.8943],\n",
      "         [-1.1459, -0.4556,  0.3709,  ..., -0.7938,  0.3033, -1.2805],\n",
      "         ...,\n",
      "         [-0.5247, -0.5659, -0.2109,  ..., -0.5649,  0.1256, -0.4024],\n",
      "         [-0.5364, -0.7499, -0.0893,  ..., -0.5820, -0.1968, -0.6426],\n",
      "         [-0.4638, -0.6111,  0.1013,  ..., -0.1594, -0.2700, -0.0995]],\n",
      "\n",
      "        [[-0.1159,  0.2341, -0.6071,  ..., -0.1445, -0.5660,  0.0293],\n",
      "         [ 0.0424,  0.2457, -0.2148,  ..., -0.3308, -1.1102, -0.1638],\n",
      "         [ 0.1835, -0.5888, -0.0422,  ...,  0.2524, -0.6551,  0.1922],\n",
      "         ...,\n",
      "         [ 0.2668, -0.3825, -0.5525,  ..., -0.2165, -1.6751, -0.1300],\n",
      "         [ 0.1795, -0.6164, -0.5118,  ..., -0.1704, -0.9673, -0.2105],\n",
      "         [-0.0329, -0.5298, -0.3802,  ..., -0.2019, -0.9358, -0.1892]],\n",
      "\n",
      "        [[-3.0914, -0.9809, -0.9798,  ...,  0.0775,  1.3699, -1.4695],\n",
      "         [-2.1471,  0.3410, -1.8542,  ...,  0.5251,  0.9950, -1.1488],\n",
      "         [-2.1065, -0.2288, -0.7742,  ...,  0.2884, -0.0799, -1.4217],\n",
      "         ...,\n",
      "         [-2.7998, -0.5716, -0.8788,  ...,  0.2016, -0.1168, -0.9390],\n",
      "         [-2.1824, -0.5662, -0.9362,  ...,  0.5888,  0.2873, -1.3802],\n",
      "         [-2.6323, -0.4420, -0.3806,  ...,  0.9057,  0.4845, -1.3334]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'decoder_output' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q5/3bn8p2n513s7x50v3j63cn6r0000gn/T/ipykernel_86738/2093733732.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output shape: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf-test/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_Tensorflow2/re-implementation-transformer/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_input, decoder_input)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0moutput_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf-test/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_Tensorflow2/re-implementation-transformer/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, decoder_input, encoder_output)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# decoder_output = x.type(torch.LongTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# print(decoder_output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0moutput_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'decoder_output' referenced before assignment"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, outputs = data\n",
    "        print(\"input shape: \", inputs.shape)\n",
    "        temp = transformer(inputs, outputs)\n",
    "        print(\"output shape: \", temp.shape)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a38b83aeb1ea4339894febc55f8dc589b6819da101b0f16fbec59eab151f047a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
